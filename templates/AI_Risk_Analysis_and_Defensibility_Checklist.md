# Checklist de Análise de Riscos e Defensabilidade em IA

## Descrição

Este artefato operacionaliza o pilar **Defensável**. Ele guia a equipe na identificação, avaliação e planejamento da mitigação de riscos relacionados à justiça, privacidade, segurança e transparência da solução. Não é apenas uma lista de verificação, mas uma ferramenta para fomentar a discussão crítica e registrar o compromisso da equipe com a construção de uma IA responsável.

## Instruções de Preenchimento

Conduzido pelo líder da atividade, o grupo preenche colaborativamente cada seção, iniciando com um brainstorming de riscos e finalizando com um plano de ação concreto para os itens mais críticos.

### 1. Análise de Justiça e Viés (Fairness & Bias)

- **Instruções**: Avalie se a IA pode gerar resultados que reforcem estereótipos negativos, ou que performem de maneira desigual para diferentes grupos demográficos (gênero, raça, etc.).

### 2. Análise de Privacidade e Dados

- **Instruções**: Verifique a conformidade com a LGPD e outras regulações. Avalie os riscos de vazamento de dados do usuário ou de inferência de informações sensíveis não fornecidas explicitamente.

### 3. Análise de Segurança e Robustez

- **Instruções**: Investigue vulnerabilidades a ataques comuns em LLMs, como *Prompt Injection* e *Jailbreaking*. Avalie a probabilidade de a IA gerar conteúdo tóxico, ilegal ou prejudicial.

### 4. Análise de Transparência e Explicabilidade

- **Instruções**: Analise se o usuário compreende que está interagindo com uma IA e quais são suas limitações. Avalie se o sistema oferece justificativas para suas respostas quando necessário.

### 5. Matriz de Priorização de Riscos

- **Instruções**: Posicione os riscos identificados numa matriz de Impacto vs. Probabilidade para focar nos mais críticos.

### 6. Plano de Mitigação

- **Instruções**: Para cada risco de alta prioridade, descreva a ação de mitigação, o responsável e como o sucesso da mitigação será verificado.
